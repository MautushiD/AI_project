{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -q super-gradients==3.1.1\n",
    "#!pip install -q roboflow\n",
    "#!pip install -q supervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -q super-gradients==3.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting super-gradients\n",
      "  Using cached super_gradients-3.4.1-py3-none-any.whl (12.0 MB)\n",
      "Requirement already satisfied: matplotlib>=3.3.4 in c:\\users\\admin\\anaconda3\\envs\\introai\\lib\\site-packages (from super-gradients) (3.3.4)\n",
      "Requirement already satisfied: numpy<=1.23 in c:\\users\\admin\\anaconda3\\envs\\introai\\lib\\site-packages (from super-gradients) (1.19.5)\n",
      "Collecting boto3>=1.17.15\n",
      "  Using cached boto3-1.23.10-py3-none-any.whl (132 kB)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in c:\\users\\admin\\anaconda3\\envs\\introai\\lib\\site-packages (from super-gradients) (58.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'c:\\Users\\Admin\\anaconda3\\envs\\introAI\\python.exe' 'c:\\Users\\Admin\\anaconda3\\envs\\introAI\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py' get_requires_for_build_wheel 'C:\\Users\\Admin\\AppData\\Local\\Temp\\tmpv390iugk'\n",
      "       cwd: C:\\Users\\Admin\\AppData\\Local\\Temp\\pip-install-dlbznab9\\onnx_8f627bbea28848fea970345f137a4f6d\n",
      "  Complete output (19 lines):\n",
      "  fatal: not a git repository (or any of the parent directories): .git\n",
      "  Traceback (most recent call last):\n",
      "    File \"c:\\Users\\Admin\\anaconda3\\envs\\introAI\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py\", line 349, in <module>\n",
      "      main()\n",
      "    File \"c:\\Users\\Admin\\anaconda3\\envs\\introAI\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py\", line 331, in main\n",
      "      json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "    File \"c:\\Users\\Admin\\anaconda3\\envs\\introAI\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py\", line 117, in get_requires_for_build_wheel\n",
      "      return hook(config_settings)\n",
      "    File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\pip-build-env-j_9kz0dn\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 163, in get_requires_for_build_wheel\n",
      "      config_settings, requirements=['wheel'])\n",
      "    File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\pip-build-env-j_9kz0dn\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 143, in _get_build_requires\n",
      "      self.run_setup()\n",
      "    File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\pip-build-env-j_9kz0dn\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 268, in run_setup\n",
      "      self).run_setup(setup_script=setup_script)\n",
      "    File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\pip-build-env-j_9kz0dn\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 158, in run_setup\n",
      "      exec(compile(code, __file__, 'exec'), locals())\n",
      "    File \"setup.py\", line 82, in <module>\n",
      "      assert CMAKE, \"Could not find cmake executable!\"\n",
      "  AssertionError: Could not find cmake executable!\n",
      "  ----------------------------------------\n",
      "WARNING: Discarding https://files.pythonhosted.org/packages/6c/f6/215ba9e8d2587755df363170e3be54892b087bad0a99935fe456f7555255/onnx-1.13.0.tar.gz#sha256=410b39950367857f97b65093681fe2495a2e23d63777a8aceaf96c56a16d166e (from https://pypi.org/simple/onnx/). Command errored out with exit status 1: 'c:\\Users\\Admin\\anaconda3\\envs\\introAI\\python.exe' 'c:\\Users\\Admin\\anaconda3\\envs\\introAI\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py' get_requires_for_build_wheel 'C:\\Users\\Admin\\AppData\\Local\\Temp\\tmpv390iugk' Check the logs for full command output.\n",
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'c:\\Users\\Admin\\anaconda3\\envs\\introAI\\python.exe' 'c:\\Users\\Admin\\anaconda3\\envs\\introAI\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py' get_requires_for_build_wheel 'C:\\Users\\Admin\\AppData\\Local\\Temp\\tmp9664k6s5'\n",
      "       cwd: C:\\Users\\Admin\\AppData\\Local\\Temp\\pip-install-dlbznab9\\onnx_f8f69d584603413db352774f2301e914\n",
      "  Complete output (19 lines):\n",
      "  fatal: not a git repository (or any of the parent directories): .git\n",
      "  Traceback (most recent call last):\n",
      "    File \"c:\\Users\\Admin\\anaconda3\\envs\\introAI\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py\", line 349, in <module>\n",
      "      main()\n",
      "    File \"c:\\Users\\Admin\\anaconda3\\envs\\introAI\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py\", line 331, in main\n",
      "      json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "    File \"c:\\Users\\Admin\\anaconda3\\envs\\introAI\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py\", line 117, in get_requires_for_build_wheel\n",
      "      return hook(config_settings)\n",
      "    File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\pip-build-env-4amfrypa\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 163, in get_requires_for_build_wheel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting coverage~=5.3.1\n",
      "  Using cached coverage-5.3.1-cp36-cp36m-win_amd64.whl (211 kB)\n",
      "Collecting opencv-python>=4.5.1\n",
      "  Using cached opencv-python-4.8.1.78.tar.gz (92.1 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Collecting torchmetrics==0.8\n",
      "  Using cached torchmetrics-0.8.0-py3-none-any.whl (408 kB)\n",
      "Collecting stringcase>=1.2.0\n",
      "  Downloading stringcase-1.2.0.tar.gz (3.0 kB)\n",
      "Collecting pycocotools==2.0.6\n",
      "  Downloading pycocotools-2.0.6.tar.gz (24 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Requirement already satisfied: torch>=1.9.0 in c:\\users\\admin\\anaconda3\\envs\\introai\\lib\\site-packages (from super-gradients) (1.10.2)\n",
      "Collecting onnx==1.13.0\n",
      "  Downloading onnx-1.13.0.tar.gz (10.4 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'error'\n",
      "Collecting super-gradients\n",
      "  Using cached super_gradients-3.4.0-py3-none-any.whl (12.0 MB)\n",
      "  Using cached super_gradients-3.3.1-py3-none-any.whl (6.5 MB)\n",
      "  Using cached super_gradients-3.3.0-py3-none-any.whl (6.5 MB)\n",
      "Collecting data-gradients>=0.2.0\n",
      "  Downloading data_gradients-0.3.0-py3-none-any.whl (458 kB)\n",
      "Collecting super-gradients\n",
      "  Using cached super_gradients-3.2.1-py3-none-any.whl (6.4 MB)\n",
      "  Using cached super_gradients-3.2.0-py3-none-any.whl (6.4 MB)\n",
      "  Using cached super_gradients-3.1.3-py3-none-any.whl (1.0 MB)\n",
      "  Using cached super_gradients-3.1.2-py3-none-any.whl (983 kB)\n",
      "  Using cached super_gradients-3.1.1-py3-none-any.whl (964 kB)\n",
      "  Using cached super_gradients-3.1.0-py3-none-any.whl (965 kB)\n",
      "  Using cached super_gradients-3.0.9-py3-none-any.whl (938 kB)\n",
      "  Using cached super_gradients-3.0.8-py3-none-any.whl (892 kB)\n",
      "  Using cached super_gradients-3.0.7-py3-none-any.whl (794 kB)\n",
      "  Using cached super_gradients-3.0.6-py3-none-any.whl (762 kB)\n",
      "  Using cached super_gradients-3.0.5-py3-none-any.whl (748 kB)\n",
      "  Using cached super_gradients-3.0.4-py3-none-any.whl (748 kB)\n",
      "  Using cached super_gradients-3.0.3-py3-none-any.whl (732 kB)\n",
      "  Using cached super_gradients-3.0.2-py3-none-any.whl (664 kB)\n",
      "  Using cached super_gradients-3.0.1-py3-none-any.whl (635 kB)\n",
      "Collecting pycocotools==2.0.4\n",
      "  Using cached pycocotools-2.0.4.tar.gz (106 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Collecting hydra-core>=1.2.0\n",
      "  Using cached hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
      "Collecting onnx>=1.10.1\n",
      "  Downloading onnx-1.14.1.tar.gz (11.3 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'error'\n",
      "  Downloading onnx-1.14.0.tar.gz (11.3 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'error'\n",
      "  Downloading onnx-1.13.1.tar.gz (10.4 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'error'\n",
      "  Downloading onnx-1.12.0.tar.gz (10.1 MB)\n",
      "  Downloading onnx-1.11.0-cp36-cp36m-win_amd64.whl (11.2 MB)\n",
      "Collecting pyparsing==2.4.5\n",
      "  Using cached pyparsing-2.4.5-py2.py3-none-any.whl (67 kB)\n",
      "Collecting omegaconf\n",
      "  Using cached omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "Collecting Deprecated>=1.2.11\n",
      "  Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting treelib==1.6.1\n",
      "  Using cached treelib-1.6.1.tar.gz (24 kB)\n",
      "Collecting psutil>=5.8.0\n",
      "  Using cached psutil-5.9.6-cp36-cp36m-win_amd64.whl (255 kB)\n",
      "Collecting termcolor==1.1.0\n",
      "  Using cached termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting sphinx-rtd-theme\n",
      "  Using cached sphinx_rtd_theme-1.3.0-py2.py3-none-any.whl (2.8 MB)\n",
      "Requirement already satisfied: packaging>=20.4 in c:\\users\\admin\\anaconda3\\envs\\introai\\lib\\site-packages (from super-gradients) (21.3)\n",
      "Collecting jsonschema>=3.2.0\n",
      "  Using cached jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\n",
      "Collecting onnxruntime\n",
      "  Using cached onnxruntime-1.10.0-cp36-cp36m-win_amd64.whl (5.2 MB)\n",
      "Collecting torchvision>=0.10.0\n",
      "  Using cached torchvision-0.11.3-cp36-cp36m-win_amd64.whl (985 kB)\n",
      "Collecting super-gradients\n",
      "  Using cached super_gradients-3.0.0-py3-none-any.whl (615 kB)\n",
      "  Using cached super_gradients-2.6.0-py3-none-any.whl (11.0 MB)\n",
      "Collecting deci-lab-client==2.38.0\n",
      "  Using cached deci_lab_client-2.38.0-py3-none-any.whl (219 kB)\n",
      "Collecting super-gradients\n",
      "  Using cached super_gradients-2.5.0-py3-none-any.whl (11.0 MB)\n",
      "  Using cached super_gradients-2.2.0-py3-none-any.whl (10.9 MB)\n",
      "  Using cached super_gradients-2.1.0-py3-none-any.whl (23.0 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      config_settings, requirements=['wheel'])\n",
      "    File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\pip-build-env-4amfrypa\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 143, in _get_build_requires\n",
      "      self.run_setup()\n",
      "    File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\pip-build-env-4amfrypa\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 268, in run_setup\n",
      "      self).run_setup(setup_script=setup_script)\n",
      "    File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\pip-build-env-4amfrypa\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 158, in run_setup\n",
      "      exec(compile(code, __file__, 'exec'), locals())\n",
      "    File \"setup.py\", line 85, in <module>\n",
      "      assert CMAKE, \"Could not find cmake executable!\"\n",
      "  AssertionError: Could not find cmake executable!\n",
      "  ----------------------------------------\n",
      "WARNING: Discarding https://files.pythonhosted.org/packages/8f/71/1543d8dad6a26df1da8953653ebdbedacea9f1a5bcd023fe10f8c5f66d63/onnx-1.14.1.tar.gz#sha256=70903afe163643bd71195c78cedcc3f4fa05a2af651fd950ef3acbb15175b2d1 (from https://pypi.org/simple/onnx/). Command errored out with exit status 1: 'c:\\Users\\Admin\\anaconda3\\envs\\introAI\\python.exe' 'c:\\Users\\Admin\\anaconda3\\envs\\introAI\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py' get_requires_for_build_wheel 'C:\\Users\\Admin\\AppData\\Local\\Temp\\tmp9664k6s5' Check the logs for full command output.\n",
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'c:\\Users\\Admin\\anaconda3\\envs\\introAI\\python.exe' 'c:\\Users\\Admin\\anaconda3\\envs\\introAI\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py' get_requires_for_build_wheel 'C:\\Users\\Admin\\AppData\\Local\\Temp\\tmpg1rcxxuf'\n",
      "       cwd: C:\\Users\\Admin\\AppData\\Local\\Temp\\pip-install-dlbznab9\\onnx_bc5014a6e82c41c4bf1fab23ef5c17d0\n",
      "  Complete output (19 lines):\n",
      "  fatal: not a git repository (or any of the parent directories): .git\n",
      "  Traceback (most recent call last):\n",
      "    File \"c:\\Users\\Admin\\anaconda3\\envs\\introAI\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py\", line 349, in <module>\n",
      "      main()\n",
      "    File \"c:\\Users\\Admin\\anaconda3\\envs\\introAI\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py\", line 331, in main\n",
      "      json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "    File \"c:\\Users\\Admin\\anaconda3\\envs\\introAI\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py\", line 117, in get_requires_for_build_wheel\n",
      "      return hook(config_settings)\n",
      "    File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\pip-build-env-pcuz08g2\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 163, in get_requires_for_build_wheel\n",
      "      config_settings, requirements=['wheel'])\n",
      "    File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\pip-build-env-pcuz08g2\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 143, in _get_build_requires\n",
      "      self.run_setup()\n",
      "    File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\pip-build-env-pcuz08g2\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 268, in run_setup\n",
      "      self).run_setup(setup_script=setup_script)\n",
      "    File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\pip-build-env-pcuz08g2\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 158, in run_setup\n",
      "      exec(compile(code, __file__, 'exec'), locals())\n",
      "    File \"setup.py\", line 85, in <module>\n",
      "      assert CMAKE, \"Could not find cmake executable!\"\n",
      "  AssertionError: Could not find cmake executable!\n",
      "  ----------------------------------------\n",
      "WARNING: Discarding https://files.pythonhosted.org/packages/d2/f4/8bdd479ace89b7957231157cfdfec4be629e5bbbbebe21535d6c40df6d02/onnx-1.14.0.tar.gz#sha256=43b85087c6b919de66872a043c7f4899fe6f840e11ffca7e662b2ce9e4cc2927 (from https://pypi.org/simple/onnx/). Command errored out with exit status 1: 'c:\\Users\\Admin\\anaconda3\\envs\\introAI\\python.exe' 'c:\\Users\\Admin\\anaconda3\\envs\\introAI\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py' get_requires_for_build_wheel 'C:\\Users\\Admin\\AppData\\Local\\Temp\\tmpg1rcxxuf' Check the logs for full command output.\n",
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'c:\\Users\\Admin\\anaconda3\\envs\\introAI\\python.exe' 'c:\\Users\\Admin\\anaconda3\\envs\\introAI\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py' get_requires_for_build_wheel 'C:\\Users\\Admin\\AppData\\Local\\Temp\\tmp5xjifhim'\n",
      "       cwd: C:\\Users\\Admin\\AppData\\Local\\Temp\\pip-install-dlbznab9\\onnx_dadd2e945f4f4f089fd0e75f02cdff11\n",
      "  Complete output (19 lines):\n",
      "  fatal: not a git repository (or any of the parent directories): .git\n",
      "  Traceback (most recent call last):\n",
      "    File \"c:\\Users\\Admin\\anaconda3\\envs\\introAI\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py\", line 349, in <module>\n",
      "      main()\n",
      "    File \"c:\\Users\\Admin\\anaconda3\\envs\\introAI\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py\", line 331, in main\n",
      "      json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "    File \"c:\\Users\\Admin\\anaconda3\\envs\\introAI\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py\", line 117, in get_requires_for_build_wheel\n",
      "      return hook(config_settings)\n",
      "    File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\pip-build-env-iptq05l6\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 163, in get_requires_for_build_wheel\n",
      "      config_settings, requirements=['wheel'])\n",
      "    File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\pip-build-env-iptq05l6\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 143, in _get_build_requires\n",
      "      self.run_setup()\n",
      "    File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\pip-build-env-iptq05l6\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 268, in run_setup\n",
      "      self).run_setup(setup_script=setup_script)\n",
      "    File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\pip-build-env-iptq05l6\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 158, in run_setup\n",
      "      exec(compile(code, __file__, 'exec'), locals())\n",
      "    File \"setup.py\", line 82, in <module>\n",
      "      assert CMAKE, \"Could not find cmake executable!\"\n",
      "  AssertionError: Could not find cmake executable!\n",
      "  ----------------------------------------\n",
      "WARNING: Discarding https://files.pythonhosted.org/packages/56/b5/f5889d518276061f999d7cda5714f288b1718cbbc3f538e943822626eead/onnx-1.13.1.tar.gz#sha256=0bdcc25c2c1ce4a8750e4ffbd93ae945442e7fac6e51176f38e366b74a97dfd9 (from https://pypi.org/simple/onnx/). Command errored out with exit status 1: 'c:\\Users\\Admin\\anaconda3\\envs\\introAI\\python.exe' 'c:\\Users\\Admin\\anaconda3\\envs\\introAI\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py' get_requires_for_build_wheel 'C:\\Users\\Admin\\AppData\\Local\\Temp\\tmp5xjifhim' Check the logs for full command output.\n",
      "    ERROR: Command errored out with exit status 1:\n",
      "     command: 'c:\\Users\\Admin\\anaconda3\\envs\\introAI\\python.exe' -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'C:\\\\Users\\\\Admin\\\\AppData\\\\Local\\\\Temp\\\\pip-install-dlbznab9\\\\onnx_633e69ac9dd24f9a8dafefef6671c876\\\\setup.py'\"'\"'; __file__='\"'\"'C:\\\\Users\\\\Admin\\\\AppData\\\\Local\\\\Temp\\\\pip-install-dlbznab9\\\\onnx_633e69ac9dd24f9a8dafefef6671c876\\\\setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' egg_info --egg-base 'C:\\Users\\Admin\\AppData\\Local\\Temp\\pip-pip-egg-info-u1dz382c'\n",
      "         cwd: C:\\Users\\Admin\\AppData\\Local\\Temp\\pip-install-dlbznab9\\onnx_633e69ac9dd24f9a8dafefef6671c876\\\n",
      "    Complete output (6 lines):\n",
      "    fatal: not a git repository (or any of the parent directories): .git\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"C:\\Users\\Admin\\AppData\\Local\\Temp\\pip-install-dlbznab9\\onnx_633e69ac9dd24f9a8dafefef6671c876\\setup.py\", line 81, in <module>\n",
      "        assert CMAKE, \"Could not find cmake executable!\"\n",
      "    AssertionError: Could not find cmake executable!\n",
      "    ----------------------------------------\n",
      "WARNING: Discarding https://files.pythonhosted.org/packages/2c/6a/39b0580858589a67c3322aabc2634f158391ffbf98fa410127533e7f1495/onnx-1.12.0.tar.gz#sha256=13b3e77d27523b9dbf4f30dfc9c959455859d5e34e921c44f712d69b8369eff9 (from https://pypi.org/simple/onnx/). Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.\n",
      "ERROR: Cannot install super-gradients==1.3.0, super-gradients==1.3.1, super-gradients==1.4.0, super-gradients==1.5.0, super-gradients==1.5.1, super-gradients==1.5.2, super-gradients==1.6.0, super-gradients==1.7.1, super-gradients==1.7.2, super-gradients==1.7.3, super-gradients==1.7.4, super-gradients==1.7.5, super-gradients==2.0.0, super-gradients==2.0.1, super-gradients==2.1.0, super-gradients==2.2.0, super-gradients==2.5.0, super-gradients==2.6.0, super-gradients==3.0.0, super-gradients==3.0.1, super-gradients==3.0.2, super-gradients==3.0.3, super-gradients==3.0.4, super-gradients==3.0.5, super-gradients==3.0.6, super-gradients==3.0.7, super-gradients==3.0.8, super-gradients==3.0.9, super-gradients==3.1.0, super-gradients==3.1.1, super-gradients==3.1.2, super-gradients==3.1.3, super-gradients==3.2.0, super-gradients==3.2.1, super-gradients==3.3.0, super-gradients==3.3.1, super-gradients==3.4.0 and super-gradients==3.4.1 because these package versions have conflicting dependencies.\n",
      "ERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/user_guide/#fixing-conflicting-dependencies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting CMRESHandler>=1.0.0\n",
      "  Downloading CMRESHandler-1.0.0-py3-none-any.whl (15 kB)\n",
      "Collecting super-gradients\n",
      "  Using cached super_gradients-2.0.1-py3-none-any.whl (19.4 MB)\n",
      "Collecting deci-lab-client==2.22.1\n",
      "  Using cached deci_lab_client-2.22.1-py3-none-any.whl (234 kB)\n",
      "Collecting super-gradients\n",
      "  Using cached super_gradients-2.0.0-py3-none-any.whl (19.4 MB)\n",
      "  Using cached super_gradients-1.7.5-py3-none-any.whl (19.3 MB)\n",
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.6.2-cp36-cp36m-win_amd64.whl (423.3 MB)\n",
      "Collecting super-gradients\n",
      "  Using cached super_gradients-1.7.4-py3-none-any.whl (19.3 MB)\n",
      "  Using cached super_gradients-1.7.3-py3-none-any.whl (19.3 MB)\n",
      "Collecting torchmetrics>=0.5.0\n",
      "  Using cached torchmetrics-0.8.2-py3-none-any.whl (409 kB)\n",
      "Collecting super-gradients\n",
      "  Using cached super_gradients-1.7.2-py3-none-any.whl (19.3 MB)\n",
      "  Using cached super_gradients-1.7.1-py3-none-any.whl (15.1 MB)\n",
      "  Using cached super_gradients-1.6.0-py3-none-any.whl (547 kB)\n",
      "  Using cached super_gradients-1.5.2-py3-none-any.whl (540 kB)\n",
      "  Using cached super_gradients-1.5.1-py3-none-any.whl (540 kB)\n",
      "  Using cached super_gradients-1.5.0-py3-none-any.whl (497 kB)\n",
      "  Using cached super_gradients-1.4.0-py3-none-any.whl (419 kB)\n",
      "  Using cached super_gradients-1.3.1-py3-none-any.whl (416 kB)\n",
      "  Using cached super_gradients-1.3.0-py3-none-any.whl (415 kB)\n",
      "\n",
      "The conflict is caused by:\n",
      "    super-gradients 3.4.1 depends on onnx==1.13.0\n",
      "    super-gradients 3.4.0 depends on onnx==1.13.0\n",
      "    super-gradients 3.3.1 depends on onnx==1.13.0\n",
      "    super-gradients 3.3.0 depends on onnx==1.13.0\n",
      "    super-gradients 3.2.1 depends on onnx==1.13.0\n",
      "    super-gradients 3.2.0 depends on onnx==1.13.0\n",
      "    super-gradients 3.1.3 depends on onnx==1.13.0\n",
      "    super-gradients 3.1.2 depends on onnx==1.13.0\n",
      "    super-gradients 3.1.1 depends on pillow>=9.2.0\n",
      "    super-gradients 3.1.0 depends on pillow>=9.2.0\n",
      "    super-gradients 3.0.9 depends on pillow>=9.2.0\n",
      "    super-gradients 3.0.8 depends on pillow>=9.2.0\n",
      "    super-gradients 3.0.7 depends on pillow>=9.2.0\n",
      "    super-gradients 3.0.6 depends on pillow>=9.2.0\n",
      "    super-gradients 3.0.5 depends on pillow>=9.2.0\n",
      "    super-gradients 3.0.4 depends on pillow>=9.2.0\n",
      "    super-gradients 3.0.3 depends on pillow>=9.2.0\n",
      "    super-gradients 3.0.2 depends on pillow>=9.2.0\n",
      "    super-gradients 3.0.1 depends on scipy>=1.6.1\n",
      "    super-gradients 3.0.0 depends on scipy>=1.6.1\n",
      "    super-gradients 2.6.0 depends on scipy>=1.6.1\n",
      "    super-gradients 2.5.0 depends on scipy>=1.6.1\n",
      "    super-gradients 2.2.0 depends on scipy>=1.6.1\n",
      "    super-gradients 2.1.0 depends on scipy>=1.6.1\n",
      "    super-gradients 2.0.1 depends on scipy>=1.6.1\n",
      "    super-gradients 2.0.0 depends on scipy>=1.6.1\n",
      "    super-gradients 1.7.5 depends on scipy>=1.6.1\n",
      "    super-gradients 1.7.4 depends on scipy>=1.6.1\n",
      "    super-gradients 1.7.3 depends on scipy>=1.6.1\n",
      "    super-gradients 1.7.2 depends on scipy>=1.6.1\n",
      "    super-gradients 1.7.1 depends on scipy>=1.6.1\n",
      "    super-gradients 1.6.0 depends on scipy>=1.6.1\n",
      "    super-gradients 1.5.2 depends on scipy>=1.6.1\n",
      "    super-gradients 1.5.1 depends on scipy>=1.6.1\n",
      "    super-gradients 1.5.0 depends on scipy>=1.6.1\n",
      "    super-gradients 1.4.0 depends on scipy>=1.6.1\n",
      "    super-gradients 1.3.1 depends on scipy>=1.6.1\n",
      "    super-gradients 1.3.0 depends on scipy>=1.6.1\n",
      "\n",
      "To fix this you could try to:\n",
      "1. loosen the range of package versions you've specified\n",
      "2. remove package versions to allow pip attempt to solve the dependency conflict\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install super-gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\github\\AI_project\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "HOME = os.getcwd()\n",
    "print(HOME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else \"cpu\"\n",
    "MODEL_ARCH = 'yolo_nas_l'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'super_gradients'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-e0ed695006c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msuper_gradients\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMODEL_ARCH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpretrained_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"coco\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'super_gradients'"
     ]
    }
   ],
   "source": [
    "from super_gradients.training import models\n",
    "\n",
    "model = models.get(MODEL_ARCH, pretrained_weights=\"coco\").to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Finetunning#######\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from super_gradients.training import Trainer\n",
    "\n",
    "CHECKPOINT_DIR = 'checkpoints'\n",
    "trainer = Trainer(experiment_name='yolonas_AI',\n",
    "                  ckpt_root_dir=CHECKPOINT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from super_gradients.training import dataloaders\n",
    "from super_gradients.training.dataloaders.dataloaders import coco_detection_yolo_format_train, coco_detection_yolo_format_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_params = {\n",
    "    'data_dir': 'data',\n",
    "    'train_images_dir': 'train/train_img',\n",
    "    'train_labels_dir': 'train/trainyolo',\n",
    "    'val_images_dir': 'val/val_img',\n",
    "    'val_labels_dir': 'val/valyolo',\n",
    "    'test_images_dir': 'test/test_img',\n",
    "    'test_labels_dir': 'test/testyolo',\n",
    "    'classes': ['Pedestrian', 'Cyclist', 'Car', 'Truck', 'Tram',  'Tricycle'],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class = dataset_params['classes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(classess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "train_data = coco_detection_yolo_format_train(\n",
    "    dataset_params={\n",
    "        'data_dir': dataset_params['data_dir'],\n",
    "        'images_dir': dataset_params['train_images_dir'],\n",
    "        'labels_dir': dataset_params['train_labels_dir'],\n",
    "        'classes': dataset_params['classes']\n",
    "    },\n",
    "    dataloader_params={\n",
    "        'batch_size': 16,\n",
    "        'num_workers': 2\n",
    "    }\n",
    ")\n",
    "\n",
    "val_data = coco_detection_yolo_format_val(\n",
    "    dataset_params={\n",
    "        'data_dir': dataset_params['data_dir'],\n",
    "        'images_dir': dataset_params['val_images_dir'],\n",
    "        'labels_dir': dataset_params['val_labels_dir'],\n",
    "        'classes': dataset_params['classes']\n",
    "    },\n",
    "    dataloader_params={\n",
    "        'batch_size': 16,\n",
    "        'num_workers': 2\n",
    "    }\n",
    ")\n",
    "\n",
    "test_data = coco_detection_yolo_format_val(\n",
    "    dataset_params={\n",
    "        'data_dir': dataset_params['data_dir'],\n",
    "        'images_dir': dataset_params['test_images_dir'],\n",
    "        'labels_dir': dataset_params['test_labels_dir'],\n",
    "        'classes': dataset_params['classes']\n",
    "    },\n",
    "    dataloader_params={\n",
    "        'batch_size': 16,\n",
    "        'num_workers': 2\n",
    "    }\n",
    ")\n",
    "\n",
    "clear_output()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DetectionMosaic('additional_samples_count': 3, 'non_empty_targets': False, 'prob': 1.0, 'input_dim': [640, 640], 'enable_mosaic': True, 'border_value': 114),\n",
       " DetectionRandomAffine('additional_samples_count': 0, 'non_empty_targets': False, 'degrees': 10.0, 'translate': 0.1, 'scale': [0.1, 2], 'shear': 2.0, 'target_size': [640, 640], 'enable': True, 'filter_box_candidates': True, 'wh_thr': 2, 'ar_thr': 20, 'area_thr': 0.1, 'border_value': 114),\n",
       " DetectionMixup('additional_samples_count': 1, 'non_empty_targets': True, 'input_dim': [640, 640], 'mixup_scale': [0.5, 1.5], 'prob': 1.0, 'enable_mixup': True, 'flip_prob': 0.5, 'border_value': 114),\n",
       " DetectionHSV('additional_samples_count': 0, 'non_empty_targets': False, 'prob': 1.0, 'hgain': 5, 'sgain': 30, 'vgain': 30, 'bgr_channels': (0, 1, 2), '_additional_channels_warned': False),\n",
       " DetectionHorizontalFlip('additional_samples_count': 0, 'non_empty_targets': False, 'prob': 0.5, 'max_targets': 120),\n",
       " DetectionPaddedRescale('swap': (2, 0, 1), 'input_dim': [640, 640], 'max_targets': 120, 'pad_value': 114),\n",
       " DetectionTargetsFormatTransform('additional_samples_count': 0, 'non_empty_targets': False, 'input_format': OrderedDict([('bboxes', name=bboxes length=4 format=<super_gradients.training.datasets.data_formats.bbox_formats.xyxy.XYXYCoordinateFormat object at 0x1519ac4c0>), ('labels', name=labels length=1)]), 'output_format': OrderedDict([('labels', name=labels length=1), ('bboxes', name=bboxes length=4 format=<super_gradients.training.datasets.data_formats.bbox_formats.cxcywh.CXCYWHCoordinateFormat object at 0x151a54490>)]), 'max_targets': 120, 'min_bbox_edge_size': 1, 'input_dim': [640, 640], 'targets_format_converter': <super_gradients.training.datasets.data_formats.format_converter.ConcatenatedTensorFormatConverter object at 0x2973a1e50>)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.dataset.transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching annotations: 100%|██████████| 20/20 [00:00<00:00, 179.26it/s]\n",
      "Caching annotations: 100%|██████████| 20/20 [00:00<00:00, 328.36it/s]\n",
      "[2023-10-23 14:23:53] INFO - checkpoint_utils.py - License Notification: YOLO-NAS pre-trained weights are subjected to the specific license terms and conditions detailed in \n",
      "https://github.com/Deci-AI/super-gradients/blob/master/LICENSE.YOLONAS.md\n",
      "By downloading the pre-trained weight files you agree to comply with these terms.\n"
     ]
    }
   ],
   "source": [
    "#calling the pretrained model\n",
    "from super_gradients.training import models\n",
    "model = models.get('yolo_nas_l',\n",
    "                   num_classes= len(dataset_params['classes']),\n",
    "                   pretrained_weights=\"coco\"\n",
    "                   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from super_gradients.training.losses import PPYoloELoss\n",
    "from super_gradients.training.metrics import DetectionMetrics_050\n",
    "from super_gradients.training.models.detection_models.pp_yolo_e import PPYoloEPostPredictionCallback\n",
    "\n",
    "train_params = {\n",
    "    'silent_mode': False,\n",
    "    \"average_best_models\": True,\n",
    "    \"warmup_mode\": \"linear_epoch_step\",\n",
    "    \"warmup_initial_lr\": 1e-6,\n",
    "    \"lr_warmup_epochs\": 3,\n",
    "    \"initial_lr\": 5e-4,\n",
    "    \"lr_mode\": \"cosine\",\n",
    "    \"cosine_final_lr_ratio\": 0.1,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"optimizer_params\": {\"weight_decay\": 0.0001},\n",
    "    \"zero_weight_decay_on_bias_and_bn\": True,\n",
    "    \"ema\": True,\n",
    "    \"ema_params\": {\"decay\": 0.9, \"decay_type\": \"threshold\"},\n",
    "    \"max_epochs\": 5,\n",
    "    \"mixed_precision\": False,\n",
    "    \"loss\": PPYoloELoss(\n",
    "        use_static_assigner=False,\n",
    "        num_classes=len(dataset_params['classes']),\n",
    "        reg_max=16\n",
    "    ),\n",
    "    \"valid_metrics_list\": [\n",
    "        DetectionMetrics_050(\n",
    "            score_thres=0.1,\n",
    "            top_k_predictions=300,\n",
    "            num_cls = len(dataset_params['classes']),\n",
    "            normalize_targets=True,\n",
    "            post_prediction_callback=PPYoloEPostPredictionCallback(\n",
    "                score_threshold=0.01,\n",
    "                nms_top_k=1000,\n",
    "                max_predictions=300,\n",
    "                nms_threshold=0.7\n",
    "            )\n",
    "        )\n",
    "    ],\n",
    "    \"metric_to_watch\": 'mAP@0.50'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-10-23 14:23:54] INFO - sg_trainer.py - Using EMA with params {'decay': 0.9, 'decay_type': 'threshold'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The console stream is now moved to checkpoints/yolonas_AI/console_Oct23_14_24_06.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[2023-10-23 14:24:22] INFO - sg_trainer_utils.py - TRAINING PARAMETERS:\n",
      "    - Mode:                         Single GPU\n",
      "    - Number of GPUs:               0          (0 available on the machine)\n",
      "    - Dataset size:                 49         (len(train_set))\n",
      "    - Batch size per GPU:           16         (batch_size)\n",
      "    - Batch Accumulate:             1          (batch_accumulate)\n",
      "    - Total batch size:             16         (num_gpus * batch_size)\n",
      "    - Effective Batch size:         16         (num_gpus * batch_size * batch_accumulate)\n",
      "    - Iterations per epoch:         3          (len(train_loader))\n",
      "    - Gradient updates per epoch:   3          (len(train_loader) / batch_accumulate)\n",
      "\n",
      "[2023-10-23 14:24:22] INFO - sg_trainer.py - Started training for 5 epochs (0/4)\n",
      "\n",
      "Train epoch 0:   0%|          | 0/3 [00:00<?, ?it/s][W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "Train epoch 0: 100%|██████████| 3/3 [02:12<00:00, 44.06s/it, PPYoloELoss/loss=3.59, PPYoloELoss/loss_cls=2.26, PPYoloELoss/loss_dfl=1.14, PPYoloELoss/loss_iou=0.303, gpu_mem=0]\n",
      "Validation epoch 0:   0%|          | 0/2 [00:00<?, ?it/s][W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "Validation epoch 0: 100%|██████████| 2/2 [00:31<00:00, 15.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================================\n",
      "SUMMARY OF EPOCH 0\n",
      "├── Training\n",
      "│   ├── Ppyoloeloss/loss = 3.5902\n",
      "│   ├── Ppyoloeloss/loss_cls = 2.2648\n",
      "│   ├── Ppyoloeloss/loss_dfl = 1.1352\n",
      "│   └── Ppyoloeloss/loss_iou = 0.3031\n",
      "└── Validation\n",
      "    ├── F1@0.50 = 0.0\n",
      "    ├── Map@0.50 = 0.0113\n",
      "    ├── Ppyoloeloss/loss = 3.5584\n",
      "    ├── Ppyoloeloss/loss_cls = 2.2829\n",
      "    ├── Ppyoloeloss/loss_dfl = 1.1302\n",
      "    ├── Ppyoloeloss/loss_iou = 0.2842\n",
      "    ├── Precision@0.50 = 0.0\n",
      "    └── Recall@0.50 = 0.0\n",
      "\n",
      "===========================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-10-23 14:27:08] INFO - base_sg_logger.py - Checkpoint saved in checkpoints/yolonas_AI/ckpt_best.pth\n",
      "[2023-10-23 14:27:08] INFO - sg_trainer.py - Best checkpoint overriden: validation mAP@0.50: 0.01133600901812315\n",
      "Train epoch 1:   0%|          | 0/3 [00:00<?, ?it/s][W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "Train epoch 1: 100%|██████████| 3/3 [02:07<00:00, 42.42s/it, PPYoloELoss/loss=3.24, PPYoloELoss/loss_cls=2.01, PPYoloELoss/loss_dfl=1.07, PPYoloELoss/loss_iou=0.281, gpu_mem=0]\n",
      "Validation epoch 1:   0%|          | 0/2 [00:00<?, ?it/s][W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "Validation epoch 1: 100%|██████████| 2/2 [00:50<00:00, 25.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================================\n",
      "SUMMARY OF EPOCH 1\n",
      "├── Training\n",
      "│   ├── Ppyoloeloss/loss = 3.2424\n",
      "│   │   ├── Best until now = 3.5902 (\u001b[32m↘ -0.3477\u001b[0m)\n",
      "│   │   └── Epoch N-1      = 3.5902 (\u001b[32m↘ -0.3477\u001b[0m)\n",
      "│   ├── Ppyoloeloss/loss_cls = 2.0057\n",
      "│   │   ├── Best until now = 2.2648 (\u001b[32m↘ -0.2591\u001b[0m)\n",
      "│   │   └── Epoch N-1      = 2.2648 (\u001b[32m↘ -0.2591\u001b[0m)\n",
      "│   ├── Ppyoloeloss/loss_dfl = 1.0672\n",
      "│   │   ├── Best until now = 1.1352 (\u001b[32m↘ -0.0679\u001b[0m)\n",
      "│   │   └── Epoch N-1      = 1.1352 (\u001b[32m↘ -0.0679\u001b[0m)\n",
      "│   └── Ppyoloeloss/loss_iou = 0.2813\n",
      "│       ├── Best until now = 0.3031 (\u001b[32m↘ -0.0219\u001b[0m)\n",
      "│       └── Epoch N-1      = 0.3031 (\u001b[32m↘ -0.0219\u001b[0m)\n",
      "└── Validation\n",
      "    ├── F1@0.50 = 0.0257\n",
      "    │   ├── Best until now = 0.0    (\u001b[32m↗ 0.0257\u001b[0m)\n",
      "    │   └── Epoch N-1      = 0.0    (\u001b[32m↗ 0.0257\u001b[0m)\n",
      "    ├── Map@0.50 = 0.0704\n",
      "    │   ├── Best until now = 0.0113 (\u001b[32m↗ 0.0591\u001b[0m)\n",
      "    │   └── Epoch N-1      = 0.0113 (\u001b[32m↗ 0.0591\u001b[0m)\n",
      "    ├── Ppyoloeloss/loss = 2.4848\n",
      "    │   ├── Best until now = 3.5584 (\u001b[32m↘ -1.0736\u001b[0m)\n",
      "    │   └── Epoch N-1      = 3.5584 (\u001b[32m↘ -1.0736\u001b[0m)\n",
      "    ├── Ppyoloeloss/loss_cls = 1.2997\n",
      "    │   ├── Best until now = 2.2829 (\u001b[32m↘ -0.9832\u001b[0m)\n",
      "    │   └── Epoch N-1      = 2.2829 (\u001b[32m↘ -0.9832\u001b[0m)\n",
      "    ├── Ppyoloeloss/loss_dfl = 0.9939\n",
      "    │   ├── Best until now = 1.1302 (\u001b[32m↘ -0.1363\u001b[0m)\n",
      "    │   └── Epoch N-1      = 1.1302 (\u001b[32m↘ -0.1363\u001b[0m)\n",
      "    ├── Ppyoloeloss/loss_iou = 0.2753\n",
      "    │   ├── Best until now = 0.2842 (\u001b[32m↘ -0.0089\u001b[0m)\n",
      "    │   └── Epoch N-1      = 0.2842 (\u001b[32m↘ -0.0089\u001b[0m)\n",
      "    ├── Precision@0.50 = 0.0154\n",
      "    │   ├── Best until now = 0.0    (\u001b[32m↗ 0.0154\u001b[0m)\n",
      "    │   └── Epoch N-1      = 0.0    (\u001b[32m↗ 0.0154\u001b[0m)\n",
      "    └── Recall@0.50 = 0.0787\n",
      "        ├── Best until now = 0.0    (\u001b[32m↗ 0.0787\u001b[0m)\n",
      "        └── Epoch N-1      = 0.0    (\u001b[32m↗ 0.0787\u001b[0m)\n",
      "\n",
      "===========================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-10-23 14:30:09] INFO - base_sg_logger.py - Checkpoint saved in checkpoints/yolonas_AI/ckpt_best.pth\n",
      "[2023-10-23 14:30:09] INFO - sg_trainer.py - Best checkpoint overriden: validation mAP@0.50: 0.07044921815395355\n",
      "Train epoch 2:   0%|          | 0/3 [00:00<?, ?it/s][W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "Train epoch 2: 100%|██████████| 3/3 [02:09<00:00, 43.12s/it, PPYoloELoss/loss=2.68, PPYoloELoss/loss_cls=1.44, PPYoloELoss/loss_dfl=1.01, PPYoloELoss/loss_iou=0.295, gpu_mem=0] \n",
      "Validation epoch 2:   0%|          | 0/2 [00:00<?, ?it/s][W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "Validation epoch 2: 100%|██████████| 2/2 [00:31<00:00, 15.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================================\n",
      "SUMMARY OF EPOCH 2\n",
      "├── Training\n",
      "│   ├── Ppyoloeloss/loss = 2.6829\n",
      "│   │   ├── Best until now = 3.2424 (\u001b[32m↘ -0.5596\u001b[0m)\n",
      "│   │   └── Epoch N-1      = 3.2424 (\u001b[32m↘ -0.5596\u001b[0m)\n",
      "│   ├── Ppyoloeloss/loss_cls = 1.4381\n",
      "│   │   ├── Best until now = 2.0057 (\u001b[32m↘ -0.5676\u001b[0m)\n",
      "│   │   └── Epoch N-1      = 2.0057 (\u001b[32m↘ -0.5676\u001b[0m)\n",
      "│   ├── Ppyoloeloss/loss_dfl = 1.0139\n",
      "│   │   ├── Best until now = 1.0672 (\u001b[32m↘ -0.0533\u001b[0m)\n",
      "│   │   └── Epoch N-1      = 1.0672 (\u001b[32m↘ -0.0533\u001b[0m)\n",
      "│   └── Ppyoloeloss/loss_iou = 0.2951\n",
      "│       ├── Best until now = 0.2813 (\u001b[31m↗ 0.0139\u001b[0m)\n",
      "│       └── Epoch N-1      = 0.2813 (\u001b[31m↗ 0.0139\u001b[0m)\n",
      "└── Validation\n",
      "    ├── F1@0.50 = 0.0476\n",
      "    │   ├── Best until now = 0.0257 (\u001b[32m↗ 0.0219\u001b[0m)\n",
      "    │   └── Epoch N-1      = 0.0257 (\u001b[32m↗ 0.0219\u001b[0m)\n",
      "    ├── Map@0.50 = 0.0606\n",
      "    │   ├── Best until now = 0.0704 (\u001b[31m↘ -0.0099\u001b[0m)\n",
      "    │   └── Epoch N-1      = 0.0704 (\u001b[31m↘ -0.0099\u001b[0m)\n",
      "    ├── Ppyoloeloss/loss = 3.5178\n",
      "    │   ├── Best until now = 2.4848 (\u001b[31m↗ 1.033\u001b[0m)\n",
      "    │   └── Epoch N-1      = 2.4848 (\u001b[31m↗ 1.033\u001b[0m)\n",
      "    ├── Ppyoloeloss/loss_cls = 2.1582\n",
      "    │   ├── Best until now = 1.2997 (\u001b[31m↗ 0.8585\u001b[0m)\n",
      "    │   └── Epoch N-1      = 1.2997 (\u001b[31m↗ 0.8585\u001b[0m)\n",
      "    ├── Ppyoloeloss/loss_dfl = 1.1376\n",
      "    │   ├── Best until now = 0.9939 (\u001b[31m↗ 0.1437\u001b[0m)\n",
      "    │   └── Epoch N-1      = 0.9939 (\u001b[31m↗ 0.1437\u001b[0m)\n",
      "    ├── Ppyoloeloss/loss_iou = 0.3163\n",
      "    │   ├── Best until now = 0.2753 (\u001b[31m↗ 0.041\u001b[0m)\n",
      "    │   └── Epoch N-1      = 0.2753 (\u001b[31m↗ 0.041\u001b[0m)\n",
      "    ├── Precision@0.50 = 0.0331\n",
      "    │   ├── Best until now = 0.0154 (\u001b[32m↗ 0.0178\u001b[0m)\n",
      "    │   └── Epoch N-1      = 0.0154 (\u001b[32m↗ 0.0178\u001b[0m)\n",
      "    └── Recall@0.50 = 0.122\n",
      "        ├── Best until now = 0.0787 (\u001b[32m↗ 0.0433\u001b[0m)\n",
      "        └── Epoch N-1      = 0.0787 (\u001b[32m↗ 0.0433\u001b[0m)\n",
      "\n",
      "===========================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 3:   0%|          | 0/3 [00:00<?, ?it/s][W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "Train epoch 3: 100%|██████████| 3/3 [02:07<00:00, 42.48s/it, PPYoloELoss/loss=2.51, PPYoloELoss/loss_cls=1.21, PPYoloELoss/loss_dfl=1.07, PPYoloELoss/loss_iou=0.305, gpu_mem=0]\n",
      "Validation epoch 3:   0%|          | 0/2 [00:00<?, ?it/s][W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "Validation epoch 3: 100%|██████████| 2/2 [00:31<00:00, 15.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================================\n",
      "SUMMARY OF EPOCH 3\n",
      "├── Training\n",
      "│   ├── Ppyoloeloss/loss = 2.5092\n",
      "│   │   ├── Best until now = 2.6829 (\u001b[32m↘ -0.1736\u001b[0m)\n",
      "│   │   └── Epoch N-1      = 2.6829 (\u001b[32m↘ -0.1736\u001b[0m)\n",
      "│   ├── Ppyoloeloss/loss_cls = 1.2145\n",
      "│   │   ├── Best until now = 1.4381 (\u001b[32m↘ -0.2236\u001b[0m)\n",
      "│   │   └── Epoch N-1      = 1.4381 (\u001b[32m↘ -0.2236\u001b[0m)\n",
      "│   ├── Ppyoloeloss/loss_dfl = 1.0655\n",
      "│   │   ├── Best until now = 1.0139 (\u001b[31m↗ 0.0516\u001b[0m)\n",
      "│   │   └── Epoch N-1      = 1.0139 (\u001b[31m↗ 0.0516\u001b[0m)\n",
      "│   └── Ppyoloeloss/loss_iou = 0.3048\n",
      "│       ├── Best until now = 0.2813 (\u001b[31m↗ 0.0235\u001b[0m)\n",
      "│       └── Epoch N-1      = 0.2951 (\u001b[31m↗ 0.0097\u001b[0m)\n",
      "└── Validation\n",
      "    ├── F1@0.50 = 0.013\n",
      "    │   ├── Best until now = 0.0476 (\u001b[31m↘ -0.0345\u001b[0m)\n",
      "    │   └── Epoch N-1      = 0.0476 (\u001b[31m↘ -0.0345\u001b[0m)\n",
      "    ├── Map@0.50 = 0.0078\n",
      "    │   ├── Best until now = 0.0704 (\u001b[31m↘ -0.0626\u001b[0m)\n",
      "    │   └── Epoch N-1      = 0.0606 (\u001b[31m↘ -0.0528\u001b[0m)\n",
      "    ├── Ppyoloeloss/loss = 5.9003\n",
      "    │   ├── Best until now = 2.4848 (\u001b[31m↗ 3.4155\u001b[0m)\n",
      "    │   └── Epoch N-1      = 3.5178 (\u001b[31m↗ 2.3825\u001b[0m)\n",
      "    ├── Ppyoloeloss/loss_cls = 4.056\n",
      "    │   ├── Best until now = 1.2997 (\u001b[31m↗ 2.7563\u001b[0m)\n",
      "    │   └── Epoch N-1      = 2.1582 (\u001b[31m↗ 1.8978\u001b[0m)\n",
      "    ├── Ppyoloeloss/loss_dfl = 1.6669\n",
      "    │   ├── Best until now = 0.9939 (\u001b[31m↗ 0.673\u001b[0m)\n",
      "    │   └── Epoch N-1      = 1.1376 (\u001b[31m↗ 0.5293\u001b[0m)\n",
      "    ├── Ppyoloeloss/loss_iou = 0.4043\n",
      "    │   ├── Best until now = 0.2753 (\u001b[31m↗ 0.1291\u001b[0m)\n",
      "    │   └── Epoch N-1      = 0.3163 (\u001b[31m↗ 0.088\u001b[0m)\n",
      "    ├── Precision@0.50 = 0.0078\n",
      "    │   ├── Best until now = 0.0331 (\u001b[31m↘ -0.0253\u001b[0m)\n",
      "    │   └── Epoch N-1      = 0.0331 (\u001b[31m↘ -0.0253\u001b[0m)\n",
      "    └── Recall@0.50 = 0.0671\n",
      "        ├── Best until now = 0.122  (\u001b[31m↘ -0.0548\u001b[0m)\n",
      "        └── Epoch N-1      = 0.122  (\u001b[31m↘ -0.0548\u001b[0m)\n",
      "\n",
      "===========================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train epoch 4:   0%|          | 0/3 [00:00<?, ?it/s][W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "Train epoch 4: 100%|██████████| 3/3 [02:23<00:00, 47.73s/it, PPYoloELoss/loss=2.39, PPYoloELoss/loss_cls=1.14, PPYoloELoss/loss_dfl=1.03, PPYoloELoss/loss_iou=0.295, gpu_mem=0]\n",
      "Validation epoch 4:   0%|          | 0/2 [00:00<?, ?it/s][W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "Validation epoch 4: 100%|██████████| 2/2 [00:33<00:00, 16.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================================\n",
      "SUMMARY OF EPOCH 4\n",
      "├── Training\n",
      "│   ├── Ppyoloeloss/loss = 2.3917\n",
      "│   │   ├── Best until now = 2.5092 (\u001b[32m↘ -0.1175\u001b[0m)\n",
      "│   │   └── Epoch N-1      = 2.5092 (\u001b[32m↘ -0.1175\u001b[0m)\n",
      "│   ├── Ppyoloeloss/loss_cls = 1.139\n",
      "│   │   ├── Best until now = 1.2145 (\u001b[32m↘ -0.0755\u001b[0m)\n",
      "│   │   └── Epoch N-1      = 1.2145 (\u001b[32m↘ -0.0755\u001b[0m)\n",
      "│   ├── Ppyoloeloss/loss_dfl = 1.0327\n",
      "│   │   ├── Best until now = 1.0139 (\u001b[31m↗ 0.0188\u001b[0m)\n",
      "│   │   └── Epoch N-1      = 1.0655 (\u001b[32m↘ -0.0328\u001b[0m)\n",
      "│   └── Ppyoloeloss/loss_iou = 0.2946\n",
      "│       ├── Best until now = 0.2813 (\u001b[31m↗ 0.0133\u001b[0m)\n",
      "│       └── Epoch N-1      = 0.3048 (\u001b[32m↘ -0.0102\u001b[0m)\n",
      "└── Validation\n",
      "    ├── F1@0.50 = 0.0093\n",
      "    │   ├── Best until now = 0.0476 (\u001b[31m↘ -0.0383\u001b[0m)\n",
      "    │   └── Epoch N-1      = 0.013  (\u001b[31m↘ -0.0037\u001b[0m)\n",
      "    ├── Map@0.50 = 0.0087\n",
      "    │   ├── Best until now = 0.0704 (\u001b[31m↘ -0.0617\u001b[0m)\n",
      "    │   └── Epoch N-1      = 0.0078 (\u001b[32m↗ 0.0009\u001b[0m)\n",
      "    ├── Ppyoloeloss/loss = 9.0079\n",
      "    │   ├── Best until now = 2.4848 (\u001b[31m↗ 6.5231\u001b[0m)\n",
      "    │   └── Epoch N-1      = 5.9003 (\u001b[31m↗ 3.1076\u001b[0m)\n",
      "    ├── Ppyoloeloss/loss_cls = 6.6674\n",
      "    │   ├── Best until now = 1.2997 (\u001b[31m↗ 5.3677\u001b[0m)\n",
      "    │   └── Epoch N-1      = 4.056  (\u001b[31m↗ 2.6114\u001b[0m)\n",
      "    ├── Ppyoloeloss/loss_dfl = 2.3678\n",
      "    │   ├── Best until now = 0.9939 (\u001b[31m↗ 1.374\u001b[0m)\n",
      "    │   └── Epoch N-1      = 1.6669 (\u001b[31m↗ 0.701\u001b[0m)\n",
      "    ├── Ppyoloeloss/loss_iou = 0.4626\n",
      "    │   ├── Best until now = 0.2753 (\u001b[31m↗ 0.1873\u001b[0m)\n",
      "    │   └── Epoch N-1      = 0.4043 (\u001b[31m↗ 0.0583\u001b[0m)\n",
      "    ├── Precision@0.50 = 0.0052\n",
      "    │   ├── Best until now = 0.0331 (\u001b[31m↘ -0.0279\u001b[0m)\n",
      "    │   └── Epoch N-1      = 0.0078 (\u001b[31m↘ -0.0026\u001b[0m)\n",
      "    └── Recall@0.50 = 0.0583\n",
      "        ├── Best until now = 0.122  (\u001b[31m↘ -0.0637\u001b[0m)\n",
      "        └── Epoch N-1      = 0.0671 (\u001b[31m↘ -0.0088\u001b[0m)\n",
      "\n",
      "===========================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-10-23 14:38:38] INFO - sg_trainer.py - RUNNING ADDITIONAL TEST ON THE AVERAGED MODEL...\n",
      "Validation epoch 5:   0%|          | 0/2 [00:00<?, ?it/s][W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "[W ParallelNative.cpp:229] Warning: Cannot set number of intraop threads after parallel work has started or after set_num_threads call when using native parallel backend (function set_num_threads)\n",
      "Validation epoch 5: 100%|██████████| 2/2 [00:21<00:00,  9.04s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation epoch 5: 100%|██████████| 2/2 [00:31<00:00, 15.63s/it]\n",
      "[2023-10-23 14:39:09] INFO - base_sg_logger.py - [CLEANUP] - Successfully stopped system monitoring process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================================\n",
      "SUMMARY OF EPOCH 5\n",
      "├── Training\n",
      "│   ├── Ppyoloeloss/loss = 2.3917\n",
      "│   │   ├── Best until now = 2.5092 (\u001b[32m↘ -0.1175\u001b[0m)\n",
      "│   │   └── Epoch N-1      = 2.5092 (\u001b[32m↘ -0.1175\u001b[0m)\n",
      "│   ├── Ppyoloeloss/loss_cls = 1.139\n",
      "│   │   ├── Best until now = 1.2145 (\u001b[32m↘ -0.0755\u001b[0m)\n",
      "│   │   └── Epoch N-1      = 1.2145 (\u001b[32m↘ -0.0755\u001b[0m)\n",
      "│   ├── Ppyoloeloss/loss_dfl = 1.0327\n",
      "│   │   ├── Best until now = 1.0139 (\u001b[31m↗ 0.0188\u001b[0m)\n",
      "│   │   └── Epoch N-1      = 1.0655 (\u001b[32m↘ -0.0328\u001b[0m)\n",
      "│   └── Ppyoloeloss/loss_iou = 0.2946\n",
      "│       ├── Best until now = 0.2813 (\u001b[31m↗ 0.0133\u001b[0m)\n",
      "│       └── Epoch N-1      = 0.3048 (\u001b[32m↘ -0.0102\u001b[0m)\n",
      "└── Validation\n",
      "    ├── F1@0.50 = 0.0375\n",
      "    │   ├── Best until now = 0.0476 (\u001b[31m↘ -0.0101\u001b[0m)\n",
      "    │   └── Epoch N-1      = 0.0093 (\u001b[32m↗ 0.0282\u001b[0m)\n",
      "    ├── Map@0.50 = 0.0847\n",
      "    │   ├── Best until now = 0.0704 (\u001b[32m↗ 0.0143\u001b[0m)\n",
      "    │   └── Epoch N-1      = 0.0087 (\u001b[32m↗ 0.076\u001b[0m)\n",
      "    ├── Ppyoloeloss/loss = 2.9932\n",
      "    │   ├── Best until now = 2.4848 (\u001b[31m↗ 0.5084\u001b[0m)\n",
      "    │   └── Epoch N-1      = 9.0079 (\u001b[32m↘ -6.0147\u001b[0m)\n",
      "    ├── Ppyoloeloss/loss_cls = 1.8852\n",
      "    │   ├── Best until now = 1.2997 (\u001b[31m↗ 0.5856\u001b[0m)\n",
      "    │   └── Epoch N-1      = 6.6674 (\u001b[32m↘ -4.7822\u001b[0m)\n",
      "    ├── Ppyoloeloss/loss_dfl = 0.9319\n",
      "    │   ├── Best until now = 0.9939 (\u001b[32m↘ -0.0619\u001b[0m)\n",
      "    │   └── Epoch N-1      = 2.3678 (\u001b[32m↘ -1.4359\u001b[0m)\n",
      "    ├── Ppyoloeloss/loss_iou = 0.2568\n",
      "    │   ├── Best until now = 0.2753 (\u001b[32m↘ -0.0185\u001b[0m)\n",
      "    │   └── Epoch N-1      = 0.4626 (\u001b[32m↘ -0.2058\u001b[0m)\n",
      "    ├── Precision@0.50 = 0.0206\n",
      "    │   ├── Best until now = 0.0331 (\u001b[31m↘ -0.0125\u001b[0m)\n",
      "    │   └── Epoch N-1      = 0.0052 (\u001b[32m↗ 0.0154\u001b[0m)\n",
      "    └── Recall@0.50 = 0.2397\n",
      "        ├── Best until now = 0.122  (\u001b[32m↗ 0.1178\u001b[0m)\n",
      "        └── Epoch N-1      = 0.0583 (\u001b[32m↗ 0.1814\u001b[0m)\n",
      "\n",
      "===========================================================\n"
     ]
    }
   ],
   "source": [
    "trainer.train(model=model,\n",
    "              training_params=train_params,\n",
    "              train_loader=train_data,\n",
    "              valid_loader=val_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
