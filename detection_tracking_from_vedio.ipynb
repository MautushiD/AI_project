{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description of the Notebook\n",
    "\n",
    "## Overview\n",
    "This notebook is designed to demonstrate both detection and tracking. We employ the YOLO NAS model for object detection and the DEEP SORT algorithm for tracking objects over time.\n",
    "\n",
    "## Workflow\n",
    "\n",
    "### Object Detection with YOLO NAS Model\n",
    "- **Input Video**: The source video for detection, `test_2_small.mp4`, is located in the `./test_video_input` folder.\n",
    "- **Detection Process**: The YOLO NAS model processes each frame of the video to detect objects in 2D.\n",
    "- **Output Storage**:\n",
    "  - **Detection Frames**: The frames with detected objects are saved in the `./test_video_output` folder.\n",
    "  - **Prediction Data**: The detection results are also stored in a YAML file named `./video_predictions.yaml`.\n",
    "\n",
    "### Object Tracking with DEEP SORT Algorithm\n",
    "- **Input for Tracking**: The YAML file (`./video_predictions.yaml`) containing detection data and the processed frames from the `./test_video_output` folder serve as the input for the tracking algorithm.\n",
    "- **Tracking Process**: DEEP SORT utilizes the detection data to track objects across the video frames, maintaining identity consistency.\n",
    "- **Final Output**:\n",
    "  - **Tracked Video**: The frames with tracked objects are combined to create a final output video, stored as `./output.mp4`.\n",
    "\n",
    "## Expected Outcomes\n",
    "Upon successful execution of the notebook, the user will obtain:\n",
    "- Annotated frames with object detections.\n",
    "- A YAML file containing detailed detection data.\n",
    "- A final video showcasing the tracked objects, illustrating the seamless integration of detection and tracking technologies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-12-03 22:36:40] INFO - checkpoint_utils.py - License Notification: YOLO-NAS pre-trained weights are subjected to the specific license terms and conditions detailed in \n",
      "https://github.com/Deci-AI/super-gradients/blob/master/LICENSE.YOLONAS.md\n",
      "By downloading the pre-trained weight files you agree to comply with these terms.\n",
      "[2023-12-03 22:36:40] INFO - checkpoint_utils.py - Successfully loaded pretrained weights for architecture yolo_nas_l\n"
     ]
    }
   ],
   "source": [
    "from nas_sort_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vedio prediction with NAS \n",
    "\n",
    "This step will take time depending on the length of the vedio and quality of the vedio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting Video:   0%|          | 0/286 [00:00<?, ?it/s]c:\\Users\\Admin\\anaconda3\\envs\\mix_env\\lib\\site-packages\\numpy\\lib\\arraypad.py:487: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x = np.array(x)\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\mix_env\\lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn(\n",
      "[2023-12-03 22:01:54] INFO - pipelines.py - Fusing some of the model's layers. If this takes too much memory, you can deactivate it by setting `fuse_model=False`\n",
      "Predicting Video:  79%|███████▊  | 225/286 [04:41<01:04,  1.06s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting Video: 100%|██████████| 286/286 [05:12<00:00,  1.09s/it]\n"
     ]
    }
   ],
   "source": [
    "url = \"C:/Users/Admin/github/AI_project/test_video_input/test_2_small.mp4\"\n",
    "pred_ved= yolo_nas_l.predict(url, conf=0.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### show vedio\n",
    "pred_ved.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Svaing the prediction frames in the \n",
    "> \"test_video_output\" folder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame_index, frame_prediction in enumerate(pred_ved):\n",
    "    labels = frame_prediction.prediction.labels\n",
    "    confidence = frame_prediction.prediction.confidence\n",
    "    bboxes = frame_prediction.prediction.bboxes_xyxy\n",
    "    frame_name = f\"test_video_output/frame_{frame_index}.jpg\"\n",
    "    frame_prediction.save(frame_name) # save frame as an image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save vedio prediction to yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_video_predictions_to_yaml(pred_ved, 'video_predictions.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving vedio prediction: output.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-12-03 22:27:35] INFO - feature_extractor.py - Loading weights from deep_sort_pytorch/deep_sort/deep/checkpoint/ckpt.t7... Done!\n"
     ]
    }
   ],
   "source": [
    "# Initialize the tracker\n",
    "init_trackerr()\n",
    "deep_sort_tracking_from_yaml(\"C:/Users/Admin/github/AI_project/test_video_input/test_2_small.mp4\", 'video_predictions.yaml')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
